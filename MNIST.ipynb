{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5879d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e8d07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_image_info(dataset_root):\n",
    "    data = []\n",
    "\n",
    "    for label in [\"CME\", \"Non-CME\"]:\n",
    "        label_path = os.path.join(dataset_root, label)\n",
    "\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "\n",
    "        for patient_folder in os.listdir(label_path):\n",
    "            patient_path = os.path.join(label_path, patient_folder)\n",
    "\n",
    "            if not os.path.isdir(patient_path):\n",
    "                continue\n",
    "\n",
    "            for image_name in os.listdir(patient_path):\n",
    "                if image_name.lower().endswith('.png'):\n",
    "                    image_name_lower = image_name.lower()\n",
    "                    eye = None\n",
    "\n",
    "                    # Match exact OD or OS as separate tokens\n",
    "                    if re.search(r'\\bod\\b', image_name_lower):\n",
    "                        # print(f\"right: {image_name}\")\n",
    "                        eye = 'right'\n",
    "                    elif re.search(r'\\bos\\b', image_name_lower):\n",
    "                        # print(f\"left: {image_name}\")\n",
    "                        eye = 'left'\n",
    "                    else:\n",
    "                        print(f\"eye not found: {image_name}\")\n",
    "\n",
    "                    full_path = os.path.join(patient_path, image_name)\n",
    "\n",
    "                    data.append({\n",
    "                        \"class\": label,\n",
    "                        \"patient_id\": patient_folder,\n",
    "                        \"eye\": eye,\n",
    "                        \"image_path\": full_path\n",
    "                    })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7c61bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"/data2/users/koushani/chbmit/Eye_ML/data/RV_images_cropped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0cca8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = collect_image_info(dataset_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97184168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      class patient_id    eye  \\\n",
      "55  Non-CME      CL OU   left   \n",
      "56  Non-CME      CL OU  right   \n",
      "57  Non-CME    JanC OD  right   \n",
      "58  Non-CME    MicC OU   left   \n",
      "59  Non-CME    MicC OU  right   \n",
      "60  Non-CME    RogD OD  right   \n",
      "61  Non-CME    ZarD OU   left   \n",
      "62  Non-CME    ZarD OU  right   \n",
      "63  Non-CME    PauB OU   left   \n",
      "64  Non-CME    PauB OU  right   \n",
      "\n",
      "                                           image_path  \n",
      "55  /data2/users/koushani/chbmit/Eye_ML/data/RV_im...  \n",
      "56  /data2/users/koushani/chbmit/Eye_ML/data/RV_im...  \n",
      "57  /data2/users/koushani/chbmit/Eye_ML/data/RV_im...  \n",
      "58  /data2/users/koushani/chbmit/Eye_ML/data/RV_im...  \n",
      "59  /data2/users/koushani/chbmit/Eye_ML/data/RV_im...  \n",
      "60  /data2/users/koushani/chbmit/Eye_ML/data/RV_im...  \n",
      "61  /data2/users/koushani/chbmit/Eye_ML/data/RV_im...  \n",
      "62  /data2/users/koushani/chbmit/Eye_ML/data/RV_im...  \n",
      "63  /data2/users/koushani/chbmit/Eye_ML/data/RV_im...  \n",
      "64  /data2/users/koushani/chbmit/Eye_ML/data/RV_im...  \n"
     ]
    }
   ],
   "source": [
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "162cebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_image_stats(df):\n",
    "    stats = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = row[\"image_path\"]\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale\n",
    "\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        h, w = img.shape\n",
    "        mean_intensity = img.mean()\n",
    "        std_intensity = img.std()\n",
    "        min_val = img.min()\n",
    "        max_val = img.max()\n",
    "\n",
    "        stats.append({\n",
    "            \"class\": row[\"class\"],\n",
    "            \"patient_id\": row[\"patient_id\"],\n",
    "            \"eye\": row[\"eye\"],\n",
    "            \"image_path\": img_path,\n",
    "            \"height\": h,\n",
    "            \"width\": w,\n",
    "            \"mean_intensity\": mean_intensity,\n",
    "            \"std_intensity\": std_intensity,\n",
    "            \"min_val\": min_val,\n",
    "            \"max_val\": max_val\n",
    "        })\n",
    "\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "940a1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = compute_image_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3c19a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            height        width  mean_intensity  std_intensity  min_val  \\\n",
      "count    65.000000    65.000000       65.000000      65.000000     65.0   \n",
      "mean    855.353846   857.107692       51.265301      38.373872      0.0   \n",
      "std     253.308571   253.774452       15.037393       7.521898      0.0   \n",
      "min     754.000000   758.000000       23.258173      26.721086      0.0   \n",
      "25%     760.000000   762.000000       41.369882      33.711151      0.0   \n",
      "50%     762.000000   763.000000       46.674504      37.161092      0.0   \n",
      "75%     764.000000   765.000000       59.550287      40.972291      0.0   \n",
      "max    1529.000000  1530.000000      107.041443      70.665523      0.0   \n",
      "\n",
      "         max_val  \n",
      "count  65.000000  \n",
      "mean   -1.061538  \n",
      "std     0.496139  \n",
      "min    -5.000000  \n",
      "25%    -1.000000  \n",
      "50%    -1.000000  \n",
      "75%    -1.000000  \n",
      "max    -1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Basic summaries\n",
    "print(stats_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b757764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height  width\n",
      "754     765      1\n",
      "755     765      1\n",
      "756     759      1\n",
      "758     763      1\n",
      "759     758      1\n",
      "        759      1\n",
      "        761      1\n",
      "        762      1\n",
      "        766      1\n",
      "760     759      1\n",
      "        760      4\n",
      "        761      3\n",
      "        762      4\n",
      "        763      2\n",
      "        764      1\n",
      "        765      2\n",
      "761     762      2\n",
      "        764      1\n",
      "        765      1\n",
      "        766      1\n",
      "762     761      1\n",
      "        762      5\n",
      "        763      1\n",
      "        764      2\n",
      "        765      1\n",
      "763     761      1\n",
      "        762      1\n",
      "        763      2\n",
      "        765      2\n",
      "764     763      1\n",
      "        764      2\n",
      "        765      1\n",
      "        766      1\n",
      "765     763      1\n",
      "        765      2\n",
      "        766      1\n",
      "767     764      1\n",
      "1522    1528     1\n",
      "1524    1529     2\n",
      "1526    1530     1\n",
      "1527    1530     1\n",
      "1529    1528     1\n",
      "        1530     2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check resolution distribution\n",
    "print(stats_df.groupby(['height', 'width']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1dc052c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CME        35\n",
      "Non-CME    30\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class balance\n",
    "print(stats_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e8d197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left     33\n",
      "right    32\n",
      "Name: eye, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Eye balance\n",
    "print(stats_df['eye'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc9c2f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist(stats_df[\"mean_intensity\"], bins=30)\n",
    "plt.title(\"Histogram of Mean Intensities\")\n",
    "plt.xlabel(\"Mean Pixel Intensity\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78d76eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def central_crop(img, crop_size=256):\n",
    "    h, w = img.shape[:2]\n",
    "    cx, cy = w // 2, h // 2\n",
    "    x1 = max(cx - crop_size // 2, 0)\n",
    "    y1 = max(cy - crop_size // 2, 0)\n",
    "    x2 = x1 + crop_size\n",
    "    y2 = y1 + crop_size\n",
    "    return img[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "687cae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_with_guiding_box_and_crop(image_path, guide_x=120, guide_y=100, box_size=300):\n",
    "    img = cv2.imread(image_path)\n",
    "    clone = img.copy()\n",
    "\n",
    "    # Draw guiding rectangle\n",
    "    cv2.rectangle(clone, (guide_x, guide_y), (guide_x + box_size, guide_y + box_size), (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Guiding Box - Press 's' to start manual crop\", clone)\n",
    "    key = cv2.waitKey(0)\n",
    "    if key == ord('s'):\n",
    "        roi = cv2.selectROI(\"Manual Crop\", img, showCrosshair=True)\n",
    "        cv2.destroyAllWindows()\n",
    "        x, y, w, h = roi\n",
    "        cropped = img[y:y+h, x:x+w]\n",
    "        return cropped\n",
    "    cv2.destroyAllWindows()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08739d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cropped_root = \"/data2/users/koushani/chbmit/Eye_ML/data/macular_cropped_dataset\"\n",
    "crop_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0cb184e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cropped_img \u001b[38;5;241m=\u001b[39m \u001b[43mshow_with_guiding_box_and_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/data2/users/koushani/chbmit/Eye_ML/data/RV_images_cropped/CME/ACB_OU/ACB OD close.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cropped_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanual_cropped.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, cropped_img)\n",
      "Cell \u001b[0;32mIn[53], line 7\u001b[0m, in \u001b[0;36mshow_with_guiding_box_and_crop\u001b[0;34m(image_path, guide_x, guide_y, box_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Draw guiding rectangle\u001b[39;00m\n\u001b[1;32m      6\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(clone, (guide_x, guide_y), (guide_x \u001b[38;5;241m+\u001b[39m box_size, guide_y \u001b[38;5;241m+\u001b[39m box_size), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGuiding Box - Press \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m to start manual crop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m key \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "cropped_img = show_with_guiding_box_and_crop(\"/data2/users/koushani/chbmit/Eye_ML/data/RV_images_cropped/CME/ACB_OU/ACB OD close.png\")\n",
    "if cropped_img is not None:\n",
    "    cv2.imwrite(\"manual_cropped.png\", cropped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d352190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
